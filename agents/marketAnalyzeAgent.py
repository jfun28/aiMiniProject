"""
Market Agent - ì‹œì¥ í˜„í™© ë¶„ì„ (langraph ê¸°ë°˜)
ê¸€ë¡œë²Œ(ë¶ë¯¸, ìœ ëŸ½, ì•„ì‹œì•„) ë° í•œêµ­ ì‹œì¥ë³„ íŒë§¤ëŸ‰, ì‹œì¥ ì ìœ ìœ¨, ê°€ê²© íŠ¸ë Œë“œ ë¶„ì„

langraph + tavily tool ê¸°ë°˜ êµ¬í˜„ ì˜ˆì‹œ.
"""

import sys
import os

if __name__ == "__main__":
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    sys.path.insert(0, project_root)

from typing import Dict, List, Optional
from datetime import datetime

# state, promptsëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ import
from state import AgentResult
from prompts.marketAnalyze_prompt import MARKET_ANALYZE_PROMPT

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# langraph imports
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict

# Tavily Tool
from langchain_community.tools.tavily_search import TavilySearchResults


# ---- State Definition for langraph ----
class MarketState(TypedDict, total=False):
    query_params: dict
    search_queries: List[str]
    search_results: List[dict]
    llm_response: str
    sources_count: int
    summary: str
    data: dict


def build_search_queries(query_params: Dict) -> list:
    """ê¸€ë¡œë²Œ(ë¶ë¯¸, ìœ ëŸ½, ì•„ì‹œì•„) + í•œêµ­ ì‹œì¥ ì¿¼ë¦¬ ìƒì„±"""
    period = query_params.get("period", "2024")
    companies = query_params.get("companies", [])

    regions = [
        ("ê¸€ë¡œë²Œ", "global"),
        ("ë¶ë¯¸", "North America"),
        ("ìœ ëŸ½", "Europe"),
        ("ì•„ì‹œì•„", "Asia"),
        ("í•œêµ­", "Korea"),
    ]

    queries = []
    for name, region in regions:
        # ì˜ë¬¸ ì¿¼ë¦¬ë¡œ ë³€ê²½í•˜ì—¬ ë” ë§ì€ ë°ì´í„° í™•ë³´
        queries.append(f"electric vehicle market sales volume {region} {period}")
        queries.append(f"EV market share by manufacturer {region} {period}")
        queries.append(f"electric vehicle price trends {region} {period}")
        queries.append(f"EV market growth rate {region} {period}")
        
        if companies and len(queries) < 30:  # ì¿¼ë¦¬ ìˆ˜ ì œí•œ
            for company in companies[:2]:
                queries.append(f"{company} electric vehicle sales {region} {period}")

    return queries[:25]  # ìµœëŒ€ 25ê°œ ì¿¼ë¦¬ë¡œ ì œí•œ


def format_search_results(results: list) -> str:
    """Tavily ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ë¶„ì„í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

    formatted = []
    for idx, result in enumerate(results[:30], 1):
        if isinstance(result, dict):
            title = result.get('title', 'N/A')
            content = result.get('content', result.get('snippet', 'N/A'))
            url = result.get('url', 'N/A')
            score = result.get('score', 'N/A')  # Tavily relevance score

            formatted.append(f"""
[ì¶œì²˜ {idx}]
ì œëª©: {title}
URL: {url}
ê´€ë ¨ë„: {score}
ë‚´ìš©: {content}
{'='*80}""")
        elif isinstance(result, str):
            # ë¬¸ìì—´ì¸ ê²½ìš°
            formatted.append(f"""
[ì¶œì²˜ {idx}]
ë‚´ìš©: {result}
{'='*80}""")

    return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"


def search_with_tavily(state: MarketState) -> MarketState:
    """langraph ë…¸ë“œ: Tavilyë¡œ ì¿¼ë¦¬ë“¤ ê²€ìƒ‰"""
    queries = state.get('search_queries', [])
    
    # max_resultsë¥¼ 3ìœ¼ë¡œ ì¤„ì—¬ì„œ API í˜¸ì¶œ ìµœì í™”
    tavily = TavilySearchResults(max_results=3)
    search_results = []
    
    for query in queries[:15]:  # ìµœëŒ€ 15ê°œ ì¿¼ë¦¬ë§Œ ì‹¤í–‰
        print(f"  [ê²€ìƒ‰] Tavily: {query}")
        try:
            results = tavily.invoke(query)
            if isinstance(results, list):
                search_results.extend(results)
            else:
                search_results.append(results)
        except Exception as e:
            print(f"    [ê²½ê³ ] ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            continue
    
    return {
        **state,
        "search_results": search_results,
    }


def llm_analyze_node(state: MarketState, llm=None, prompt_template=None) -> MarketState:
    """langraph ë…¸ë“œ: LLMì„ í†µí•œ ë¶„ì„"""
    formatted_results = format_search_results(state.get("search_results", []))
    sources_count = len(state.get('search_results', []))
    
    # í”„ë¡¬í”„íŠ¸ì— sources_count ì¶”ê°€
    full_prompt = prompt_template.replace("{sources_count}", str(sources_count))
    prompt = ChatPromptTemplate.from_template(full_prompt)
    chain = prompt | llm
    
    try:
        print(f"  [LLM] ë¶„ì„ ì¤‘... ({sources_count}ê°œ ìë£Œ ê¸°ë°˜)")
        response = chain.invoke({
            "query_params": str(state.get("query_params", {})),
            "search_results": formatted_results
        })
        
        print(f"  [ì™„ë£Œ] LLM ë¶„ì„ ì™„ë£Œ (ì‘ë‹µ ê¸¸ì´: {len(response.content)} ì)")
        
        return {
            **state,
            "llm_response": response.content,
            "sources_count": sources_count,
        }
    except Exception as e:
        print(f"    [ì˜¤ë¥˜] LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return {
            **state,
            "llm_response": f"# ë¶„ì„ ì˜¤ë¥˜\n\në¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "sources_count": sources_count,
        }


def structure_result_node(state: MarketState) -> MarketState:
    """langraph ë…¸ë“œ: ê²°ê³¼ êµ¬ì¡°í™” ë° ì„¹ì…˜ ì¶”ì¶œ"""
    llm_response = state.get("llm_response", "ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
    
    # LLM ì‘ë‹µì—ì„œ ì£¼ìš” ì„¹ì…˜ ì¶”ì¶œ ì‹œë„
    def extract_section(content: str, section_marker: str) -> str:
        """Markdownì—ì„œ íŠ¹ì • ì„¹ì…˜ ì¶”ì¶œ"""
        try:
            if section_marker in content:
                start_idx = content.find(section_marker)
                # ë‹¤ìŒ ## ë˜ëŠ” # ê¹Œì§€ ì¶”ì¶œ
                next_section = content.find("\n## ", start_idx + len(section_marker))
                if next_section == -1:
                    next_section = content.find("\n# ", start_idx + len(section_marker))
                
                if next_section != -1:
                    return content[start_idx:next_section].strip()
                else:
                    return content[start_idx:].strip()
        except:
            pass
        return f"{section_marker}\në°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"
    
    # ê° ì„¹ì…˜ ì¶”ì¶œ
    executive_summary = extract_section(llm_response, "## ğŸ“Š Executive Summary")
    global_analysis = extract_section(llm_response, "## ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥ ìƒì„¸ ë¶„ì„")
    korea_analysis = extract_section(llm_response, "## ğŸ‡°ğŸ‡· í•œêµ­ ì‹œì¥ ìƒì„¸ ë¶„ì„")
    investment_insights = extract_section(llm_response, "## ğŸ’¡ ë¹„êµ ë¶„ì„ ë° íˆ¬ì ì‹œì‚¬ì ")
    
    return {
        **state,
        "data": {
            "executive_summary": executive_summary,
            "global_analysis": global_analysis,
            "korea_analysis": korea_analysis,
            "investment_insights": investment_insights,
            "sources_count": state.get("sources_count", 0),
            "search_queries_count": len(state.get("search_queries", [])),
            "full_report": llm_response,
        },
        "summary": llm_response,  # ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ summaryë¡œ ë°˜í™˜
        "search_results": state.get("search_results", []),  # ê²€ìƒ‰ ê²°ê³¼ ìœ ì§€
    }


class MarketAgent:
    """ì‹œì¥ ë¶„ì„ ì—ì´ì „íŠ¸(langraph & tavily ê¸°ë°˜)"""
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.agent_name = "Market Agent"
        self.prompt_template = MARKET_ANALYZE_PROMPT

        # langraph StateGraph ìƒì„±
        self.graph = StateGraph(MarketState)

        # ë…¸ë“œ ì •ì˜
        def build_query_node(state: MarketState) -> MarketState:
            queries = build_search_queries(state.get("query_params", {}))
            return {
                **state,
                "search_queries": queries
            }

        self.graph.add_node("query_builder", build_query_node)
        self.graph.add_node("tavily_search", search_with_tavily)
        
        # LLM ë¶„ì„ ë…¸ë“œ (í´ë¡œì € ì‚¬ìš©)
        def llm_node_wrapper(state: MarketState) -> MarketState:
            return llm_analyze_node(state, llm=self.llm, prompt_template=self.prompt_template)
        
        self.graph.add_node("llm_analyze", llm_node_wrapper)
        self.graph.add_node("struct_result", structure_result_node)

        # ì‹œì‘ì  ì„¤ì •
        self.graph.set_entry_point("query_builder")

        # ì—£ì§€ ì—°ê²°
        self.graph.add_edge("query_builder", "tavily_search")
        self.graph.add_edge("tavily_search", "llm_analyze")
        self.graph.add_edge("llm_analyze", "struct_result")
        self.graph.add_edge("struct_result", END)

        # ê·¸ë˜í”„ ì»´íŒŒì¼
        self.compiled = self.graph.compile()

    def analyze(self, query_params: Dict) -> AgentResult:
        """langraph ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰"""
        print(f"\n[{self.agent_name}] ê¸€ë¡œë²Œ/í•œêµ­ ì‹œì¥ ë¶„ì„ ì‹œì‘(langraph + tavily)...")
        try:
            # langraph ì‹¤í–‰
            result_dict = self.compiled.invoke({"query_params": query_params})

            result_data = result_dict.get("data", {})
            summary = result_dict.get("summary", "ë¶„ì„ ê²°ê³¼ ì—†ìŒ")

            # ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
            search_results = result_dict.get("search_results", [])

            sources = []
            for idx, result in enumerate(search_results, 1):
                if isinstance(result, dict):
                    title = result.get("title", "ì œëª© ì—†ìŒ")
                    url = result.get("url", "")
                    content = result.get("content", result.get("snippet", ""))
                    score = result.get("score", None)

                    # ì¶œì²˜ ì •ë³´ ì €ì¥
                    source_entry = {
                        "id": idx,
                        "title": title,
                        "url": url,
                        "snippet": content[:300] if content else "",  # ë” ê¸´ ë°œì·Œë¬¸
                    }

                    # Tavily relevance scoreê°€ ìˆìœ¼ë©´ ì¶”ê°€
                    if score is not None:
                        source_entry["relevance_score"] = score

                    sources.append(source_entry)

            print(f"[{self.agent_name}] ë¶„ì„ ì™„ë£Œ âœ“ (ì¶œì²˜: {len(sources)}ê°œ)")

            return AgentResult(
                agent_name=self.agent_name,
                status="success",
                data=result_data,
                summary=summary,
                timestamp=datetime.now(),
                sources=sources
            )
        except Exception as e:
            print(f"[{self.agent_name}] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            traceback.print_exc()
            
            return AgentResult(
                agent_name=self.agent_name,
                status="failed",
                data={},
                summary="",
                timestamp=datetime.now(),
                error_message=str(e)
            )


def create_market_agent(llm: ChatOpenAI) -> MarketAgent:
    """Market Agent ìƒì„± (langraph + tavily tool)"""
    return MarketAgent(llm)


# ======= ë‹¨ë… ì‹¤í–‰ì„ ìœ„í•œ main í•¨ìˆ˜ =======
if __name__ == "__main__":
    import dotenv
    dotenv.load_dotenv()

    print("\n" + "="*70)
    print("Market Agent(langraph + tavily) ë‹¨ë… í…ŒìŠ¤íŠ¸")
    print("="*70)

    # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",  # ë” ì•ˆì •ì ì¸ ëª¨ë¸ë¡œ ë³€ê²½
            temperature=0.2,
        )
        print("[OK] OpenAI API ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"[ERROR] OpenAI API ì—°ë™ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # Agent ìƒì„±
    agent = create_market_agent(llm)

    query_params = {
        "region": "í•œêµ­",
        "period": f"{datetime.now().year}",
        "companies": ["Tesla", "Hyundai", "BYD"],
        "focus_areas": ["ì‹œì¥ ì ìœ ìœ¨", "ê°€ê²©", "ì„±ì¥ë¥ "]
    }

    print(f"\n[ì„¤ì •] ë¶„ì„ íŒŒë¼ë¯¸í„°:")
    print(f"   - ì§€ì—­: {query_params['region']}")
    print(f"   - ê¸°ê°„: {query_params['period']}")
    print(f"   - ê¸°ì—…: {', '.join(query_params['companies'])}")
    print()

    # ë¶„ì„ ì‹¤í–‰
    result = agent.analyze(query_params)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ë¶„ì„ ê²°ê³¼")
    print("="*70)
    print(f"\nìƒíƒœ: {result.status}")
    print(f"íƒ€ì„ìŠ¤íƒ¬í”„: {result.timestamp}")
    
    if result.status == "success":
        # ì „ì²´ ë¦¬í¬íŠ¸ ì¶œë ¥
        print("\n" + "="*70)
        print("ì „ì²´ ë¦¬í¬íŠ¸")
        print("="*70)
        print(result.summary)
        
        print("\n" + "="*70)
        print("êµ¬ì¡°í™”ëœ ë°ì´í„°")
        print("="*70)
        print(f"ë°ì´í„° ì†ŒìŠ¤: {result.data.get('sources_count', 0)}ê°œ")
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {result.data.get('search_queries_count', 0)}ê°œ")
        
        # ì„¹ì…˜ë³„ ë¯¸ë¦¬ë³´ê¸°
        if 'executive_summary' in result.data:
            print(f"\nExecutive Summary ë¯¸ë¦¬ë³´ê¸°:")
            preview = result.data['executive_summary'][:200]
            print(f"{preview}...")
    else:
        print(f"\nì˜¤ë¥˜: {result.error_message}")
    
    print("\n" + "="*70)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*70)